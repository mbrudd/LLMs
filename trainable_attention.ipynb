{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d9f3bcb",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mbrudd/LLMs/blob/main/trainable_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33a1a1",
   "metadata": {
    "id": "7c33a1a1"
   },
   "source": [
    "# Attention with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c78b079a",
   "metadata": {
    "id": "c78b079a"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c0c81b",
   "metadata": {
    "id": "d1c0c81b"
   },
   "outputs": [],
   "source": [
    "inputs = torch.nn.Embedding( 4, 8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "oNX4cULRxBVk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNX4cULRxBVk",
    "outputId": "bf533d32-7ab7-4a18-9199-4831562708d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3759,  0.0686,  0.7031,  0.0935, -0.0464, -0.4952,  0.8338,  1.1267],\n",
       "        [-0.6018, -0.2695,  0.3440, -1.1668, -0.9852,  0.4084, -0.0257, -0.0238],\n",
       "        [-1.0834, -0.8992, -0.9997, -1.0471,  0.6966,  1.0558, -0.3086,  0.1166],\n",
       "        [-0.8312,  0.2855, -0.0538, -0.3936, -1.2552, -0.2012, -0.8806, -0.0192]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.weight\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sTBV2KZYxCLY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTBV2KZYxCLY",
    "outputId": "7a7441ce-d882-4b7d-8823-43e7c0d9f49d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3759,  0.0686,  0.7031,  0.0935, -0.0464, -0.4952,  0.8338,  1.1267],\n",
       "        [-0.6018, -0.2695,  0.3440, -1.1668, -0.9852,  0.4084, -0.0257, -0.0238],\n",
       "        [-1.0834, -0.8992, -0.9997, -1.0471,  0.6966,  1.0558, -0.3086,  0.1166],\n",
       "        [-0.8312,  0.2855, -0.0538, -0.3936, -1.2552, -0.2012, -0.8806, -0.0192]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.data\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "QOwlthXbxb38",
   "metadata": {
    "id": "QOwlthXbxb38"
   },
   "outputs": [],
   "source": [
    "# set dimensions\n",
    "d_in = 8\n",
    "d_out = 6\n",
    "\n",
    "# create weight matrices\n",
    "W_q = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
    "W_k = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
    "W_v = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sNXSVRxtyUEq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNXSVRxtyUEq",
    "outputId": "4fe17bbf-ced8-46dc-e34d-0fff0c6f0d3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3756, -2.0649, -0.5108, -0.8182, -1.1920, -0.9123])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose an input vector and transform it into our query vector using W_q\n",
    "query = inputs[2] @ W_q\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "krMfHBPty33R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "krMfHBPty33R",
    "outputId": "36438707-eb94-4b85-fe7a-ccd7e92f7a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: tensor([[ 2.0968,  0.7871,  0.6638,  1.8078,  0.9960,  0.2127],\n",
      "        [-0.8083, -1.3694, -1.2487, -0.8687, -1.0420, -0.6535],\n",
      "        [-2.0322,  0.3496, -0.3710, -0.8335, -0.4581,  0.6089],\n",
      "        [-0.9043, -2.1913, -1.7305, -1.7807, -1.2833, -1.4691]])\n",
      "Values: tensor([[ 1.1060,  2.0203,  2.7215,  1.2079,  1.3403,  1.0632],\n",
      "        [-1.0737, -2.0347, -2.0019, -1.2446, -2.2905, -0.3585],\n",
      "        [-0.2100, -2.4208, -2.9082, -1.5892, -1.3626, -1.0998],\n",
      "        [-1.2808, -2.4287, -2.7191, -1.6241, -2.6295, -0.8259]])\n"
     ]
    }
   ],
   "source": [
    "# calculate attention scores using the keys generated by W_k:\n",
    "keys = inputs @ W_k\n",
    "values = inputs @ W_v\n",
    "print(\"Keys:\", keys)\n",
    "print(\"Values:\", values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ZCYUxgufzYJx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCYUxgufzYJx",
    "outputId": "7e9c9241-c8e1-4050-a98f-90c15f9784ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.7094,  7.1266,  2.9356, 10.9798])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = query @ keys.T\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8E3nKiYMz-B3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8E3nKiYMz-B3",
    "outputId": "7be3feb4-bbc4-4b3e-93f7-f73d3592d996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9005e-04, 1.6654e-01, 3.0093e-02, 8.0297e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = torch.softmax( attention_scores / keys.shape[-1]**0.5, dim = -1 )\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ivp5ajUU0hVX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivp5ajUU0hVX",
    "outputId": "3d728c16-7da8-47e1-9f90-dfe88ae97494"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "NDyjIXnw01bw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDyjIXnw01bw",
    "outputId": "77c652e1-60bf-4708-b3ab-3b48762a4538"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2131, -2.3611, -2.6032, -1.5588, -2.5334, -0.7556])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector = attention_weights @ values\n",
    "context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mDJu60I-08oe",
   "metadata": {
    "id": "mDJu60I-08oe"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nCNgyvAjDqJx",
   "metadata": {
    "id": "nCNgyvAjDqJx"
   },
   "outputs": [],
   "source": [
    "# here's a first version of a SimpleAttention class:\n",
    "\n",
    "class SimpleAttention( nn.Module ):\n",
    "  def __init__(self, d_in, d_out):\n",
    "    super().__init__()\n",
    "    # create weight matrices:\n",
    "    self.W_q = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
    "    self.W_k = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
    "    self.W_v = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
    "\n",
    "  # x = embedding vectors (inputs)\n",
    "  def forward( self, x ):\n",
    "    queries = x @ self.W_q\n",
    "    keys = x @ self.W_k\n",
    "    values = x @ self.W_v\n",
    "    scores = queries @ keys.T\n",
    "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
    "    context = weights @ values\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "WGqfizBVGQ6H",
   "metadata": {
    "id": "WGqfizBVGQ6H"
   },
   "outputs": [],
   "source": [
    "# here's how to use this class:\n",
    "# instantiate an instance of it:\n",
    "simple = SimpleAttention( d_in = 8, d_out = 6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "m8khSsLLGbPx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8khSsLLGbPx",
    "outputId": "83c97ed1-6c15-4aa0-c1aa-2b1c9817df8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.9563, 0.8906, 0.7216, 0.9572, 0.5428, 0.6571],\n",
       "        [0.4411, 0.5230, 0.8777, 0.2027, 0.7596, 0.7206],\n",
       "        [0.4109, 0.4746, 0.0961, 0.3563, 0.5101, 0.5325],\n",
       "        [0.0827, 0.8998, 0.2190, 0.8373, 0.3363, 0.4321],\n",
       "        [0.3779, 0.8566, 0.2960, 0.4776, 0.9894, 0.7767],\n",
       "        [0.0444, 0.2318, 0.5398, 0.7857, 0.0462, 0.5516],\n",
       "        [0.6263, 0.7638, 0.6733, 0.2554, 0.6791, 0.5256],\n",
       "        [0.2981, 0.4378, 0.1029, 0.9949, 0.2897, 0.9695]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple.W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "IDXEWBn2GhTu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDXEWBn2GhTu",
    "outputId": "d9483eba-77bf-4458-acdc-1363e90757a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4954,  1.7507,  0.8093,  1.6147,  1.4596,  1.9214],\n",
       "        [-1.6064, -2.5210, -1.3447, -1.7674, -1.9499, -1.7427],\n",
       "        [-1.6463, -2.5694, -1.3823, -1.8260, -2.0072, -1.8121],\n",
       "        [-1.6319, -2.5343, -1.3624, -1.7794, -1.9658, -1.7615]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = simple( inputs )\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "j0J4KZOZGqfu",
   "metadata": {
    "id": "j0J4KZOZGqfu"
   },
   "outputs": [],
   "source": [
    "# here's a second version of a SimpleAttention class ;\n",
    "# it uses nn.Linear to do things more efficiently\n",
    "\n",
    "class SimpleAttention( nn.Module ):\n",
    "  def __init__(self, d_in, d_out):\n",
    "    super().__init__()\n",
    "    # create weight matrices:\n",
    "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
    "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
    "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
    "\n",
    "  # x = embedding vectors (inputs)\n",
    "  def forward( self, x ):\n",
    "    queries = self.W_q( x )\n",
    "    keys = self.W_k( x )\n",
    "    values = self.W_v( x )\n",
    "    scores = queries @ keys.T\n",
    "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
    "    context = weights @ values\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Zki5jtLCI6Cu",
   "metadata": {
    "id": "Zki5jtLCI6Cu"
   },
   "outputs": [],
   "source": [
    "# here's how to use this class:\n",
    "# instantiate an instance of it:\n",
    "simple = SimpleAttention( d_in = 8, d_out = 6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "k6LcTWL9I8te",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6LcTWL9I8te",
    "outputId": "f4f6f2d6-079c-4c85-9210-7a3c6bf76b02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3545,  0.0608, -0.1222, -0.0895, -0.4415, -0.0292],\n",
       "        [-0.3666,  0.0100, -0.1073,  0.0075, -0.4131,  0.0083],\n",
       "        [-0.3545, -0.0412, -0.0744,  0.0519, -0.3728,  0.0173],\n",
       "        [-0.3551,  0.0097, -0.0977, -0.0129, -0.4042, -0.0039]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = simple( inputs )\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "oue7IwuyI_ON",
   "metadata": {
    "id": "oue7IwuyI_ON"
   },
   "outputs": [],
   "source": [
    "# the problem with this is that each context vector uses information from ALL of the embedding vectors\n",
    "# in practice, we should only use information about the preceding embedding vectors\n",
    "# to accomplish this, we'll implement causal attention AKA masked attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "L734IABHc89l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L734IABHc89l",
    "outputId": "d3baf755-2800-4380-d368-aca36fc58adb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2298, 0.2652, 0.2592, 0.2458],\n",
       "        [0.2689, 0.2290, 0.2412, 0.2610],\n",
       "        [0.3089, 0.2295, 0.1937, 0.2679],\n",
       "        [0.2037, 0.2236, 0.3170, 0.2558]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a hack to get some example weights to work with!\n",
    "# weights = simple( inputs )\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "SiNiJA_tdnIr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiNiJA_tdnIr",
    "outputId": "a0b95c43-6209-4884-ef27-c09babf578a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that these have already been normalized:\n",
    "weights.sum( dim=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "w8qwVBb3d5YE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8qwVBb3d5YE",
    "outputId": "91908225-ad9d-429f-9feb-41559e43afcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# masking method #1\n",
    "simple_mask = torch.tril( torch.ones( weights.shape[0], weights.shape[0] ) )\n",
    "simple_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aPN1GiEdeWq_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPN1GiEdeWq_",
    "outputId": "076493fd-32eb-4fbb-fb27-2d71ed7c8da9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2298, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2689, 0.2290, 0.0000, 0.0000],\n",
       "        [0.3089, 0.2295, 0.1937, 0.0000],\n",
       "        [0.2037, 0.2236, 0.3170, 0.2558]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_weights = weights*simple_mask\n",
    "masked_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "N-Ifwx0EfJs9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-Ifwx0EfJs9",
    "outputId": "ac5c40b5-443a-4b61-b330-7e09933e052a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2298, 0.4979, 0.7321, 1.0000], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_weights.sum( dim=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "gbOrqXGSfbm2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbOrqXGSfbm2",
    "outputId": "776e5184-5094-459f-82bb-c71d1a27612b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2298],\n",
       "        [0.4979],\n",
       "        [0.7321],\n",
       "        [1.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, we need to normalize the masked_weights so that each row has sum 1\n",
    "row_sums = masked_weights.sum( dim=-1, keepdim=True)\n",
    "row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ACdob5jyfi2P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACdob5jyfi2P",
    "outputId": "ac8441ef-1062-437a-d640-31efeb9c7a6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_weights = masked_weights / row_sums\n",
    "masked_weights.sum( dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0_aQEYcQf4tB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_aQEYcQf4tB",
    "outputId": "bc7275db-146c-4e00-d521-ceb4b0abdd29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5400, 0.4600, 0.0000, 0.0000],\n",
       "        [0.4219, 0.3134, 0.2646, 0.0000],\n",
       "        [0.2037, 0.2236, 0.3170, 0.2558]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "QxaUROkpgBmr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxaUROkpgBmr",
    "outputId": "19c68189-cc59-4e7e-88fd-13116854c6ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# masking method #2\n",
    "mask = torch.triu( torch.ones(weights.shape[0], weights.shape[0]), diagonal = 1 )\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9aAkggNUhUAs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aAkggNUhUAs",
    "outputId": "01ca9d8c-e586-4301-b5c6-fc8fc6a85875"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [False, False,  True,  True],\n",
       "        [False, False, False,  True],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84ev4pTZhoLD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84ev4pTZhoLD",
    "outputId": "dc355d81-9336-457d-af14-4b7d03cf728b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2298, 0.2652, 0.2592, 0.2458],\n",
       "        [0.2689, 0.2290, 0.2412, 0.2610],\n",
       "        [0.3089, 0.2295, 0.1937, 0.2679],\n",
       "        [0.2037, 0.2236, 0.3170, 0.2558]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7AW_dLvCgiA8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AW_dLvCgiA8",
    "outputId": "201749c3-b038-4aeb-cad3-680f612701a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2298,   -inf,   -inf,   -inf],\n",
       "        [0.2689, 0.2290,   -inf,   -inf],\n",
       "        [0.3089, 0.2295, 0.1937,   -inf],\n",
       "        [0.2037, 0.2236, 0.3170, 0.2558]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = weights.masked_fill( mask.bool(), -torch.inf )\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mMquJ-g1hvuq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMquJ-g1hvuq",
    "outputId": "832c13f1-13fb-43a7-db07-0703b88cdedd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5100, 0.4900, 0.0000, 0.0000],\n",
       "        [0.3553, 0.3281, 0.3166, 0.0000],\n",
       "        [0.2385, 0.2433, 0.2671, 0.2512]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_weights = torch.softmax( weights, dim=-1 )\n",
    "masked_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "v0Rl7yaikQwW",
   "metadata": {
    "id": "v0Rl7yaikQwW"
   },
   "outputs": [],
   "source": [
    "## Dropout\n",
    "# idea: randomly select some data to leave out to avoid overfitting\n",
    "dropout = nn.Dropout( 0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "Js4JQ6b9lN1p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Js4JQ6b9lN1p",
    "outputId": "1ce7a802-c040-47a4-93a1-3fb39248b5a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0199, 0.9801, 0.0000, 0.0000],\n",
       "        [0.7105, 0.6563, 0.6332, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5024]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout( masked_weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "lwzL1olBjA62",
   "metadata": {
    "id": "lwzL1olBjA62"
   },
   "outputs": [],
   "source": [
    "# we need to be able to give our LLM batches of input\n",
    "# for example:\n",
    "batches = torch.stack( (inputs, inputs), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "F9pE07dKjkPS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9pE07dKjkPS",
    "outputId": "7c8abc7d-055c-4f1d-e79a-808d8df996a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3759,  0.0686,  0.7031,  0.0935, -0.0464, -0.4952,  0.8338,\n",
       "           1.1267],\n",
       "         [-0.6018, -0.2695,  0.3440, -1.1668, -0.9852,  0.4084, -0.0257,\n",
       "          -0.0238],\n",
       "         [-1.0834, -0.8992, -0.9997, -1.0471,  0.6966,  1.0558, -0.3086,\n",
       "           0.1166],\n",
       "         [-0.8312,  0.2855, -0.0538, -0.3936, -1.2552, -0.2012, -0.8806,\n",
       "          -0.0192]],\n",
       "\n",
       "        [[ 0.3759,  0.0686,  0.7031,  0.0935, -0.0464, -0.4952,  0.8338,\n",
       "           1.1267],\n",
       "         [-0.6018, -0.2695,  0.3440, -1.1668, -0.9852,  0.4084, -0.0257,\n",
       "          -0.0238],\n",
       "         [-1.0834, -0.8992, -0.9997, -1.0471,  0.6966,  1.0558, -0.3086,\n",
       "           0.1166],\n",
       "         [-0.8312,  0.2855, -0.0538, -0.3936, -1.2552, -0.2012, -0.8806,\n",
       "          -0.0192]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ZcupJCg5zIrL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcupJCg5zIrL",
    "outputId": "f0a40051-1080-4e1d-caeb-e49b1b2f9974"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "uP2PuQ5RiCM8",
   "metadata": {
    "id": "uP2PuQ5RiCM8"
   },
   "outputs": [],
   "source": [
    "# this class needs to handle batches of input!\n",
    "\n",
    "class CausalAttention( nn.Module ):\n",
    "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "    super().__init__()\n",
    "    self.d_out = d_out\n",
    "    # create weight matrices:\n",
    "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
    "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
    "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
    "    # include dropout:\n",
    "    self.dropout = nn.Dropout( dropout )\n",
    "    # use the following to manage memory efficiently:\n",
    "    self.register_buffer(\n",
    "        'mask',\n",
    "        torch.triu( torch.ones(context_length, context_length), diagonal = 1 )\n",
    "    )\n",
    "\n",
    "  # x = embedding vectors (inputs)\n",
    "  def forward( self, x ):\n",
    "    b, num_tokens, d_in = x.shape\n",
    "    queries = self.W_q( x )\n",
    "    keys = self.W_k( x )\n",
    "    values = self.W_v( x )\n",
    "    scores = queries @ keys.transpose(1,2)\n",
    "    scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
    "    weights = self.dropout( weights )\n",
    "    context = weights @ values\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "Tqglx-lp0TFn",
   "metadata": {
    "id": "Tqglx-lp0TFn"
   },
   "outputs": [],
   "source": [
    "# instantiate a causal attention mechanism:\n",
    "causal = CausalAttention( d_in=8, d_out=6, context_length=4, dropout=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "vl4s2kdd4iNi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vl4s2kdd4iNi",
    "outputId": "020a098a-31b7-47c1-ef07-df80ddf5713f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1320, -0.1111, -0.2173,  0.5782,  0.5652, -0.0052],\n",
       "         [-0.1586, -0.1000, -0.0912,  0.0555,  0.0404, -0.2249],\n",
       "         [ 0.0056, -0.2076, -0.0674,  0.0915,  0.0285, -0.0785],\n",
       "         [-0.1241, -0.2121,  0.0519, -0.3109, -0.2811, -0.1947]],\n",
       "\n",
       "        [[-0.1320, -0.1111, -0.2173,  0.5782,  0.5652, -0.0052],\n",
       "         [-0.1586, -0.1000, -0.0912,  0.0555,  0.0404, -0.2249],\n",
       "         [ 0.0056, -0.2076, -0.0674,  0.0915,  0.0285, -0.0785],\n",
       "         [-0.1241, -0.2121,  0.0519, -0.3109, -0.2811, -0.1947]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal( batches )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "sqLa6xcW0bPw",
   "metadata": {
    "id": "sqLa6xcW0bPw"
   },
   "outputs": [],
   "source": [
    "# here's a first pass at multi-head attention\n",
    "class MultiHeadAttention( nn.Module ):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList( \n",
    "            [ CausalAttention( d_in, d_out, context_length, dropout, qkv_bias ) for _ in range(num_heads) ]\n",
    "        )\n",
    "\n",
    "    def forward( self, x ):\n",
    "        return torch.cat( [ head(x) for head in self.heads ], dim=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4-NOY2s91p61",
   "metadata": {
    "id": "4-NOY2s91p61"
   },
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention( d_in = 8, d_out = 6, context_length= 4, dropout=0, num_heads = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da73b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_out = mha( batches )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1e215e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6910, -0.1860, -0.0429,  0.4113, -0.4726,  0.1205,  0.0144,\n",
       "           0.0335, -0.1235,  0.2319, -0.4612,  0.3753, -0.5560, -0.3359,\n",
       "          -0.5808,  0.3521,  0.1915,  0.1376],\n",
       "         [-0.4432, -0.0200, -0.1760,  0.2633, -0.1150,  0.4216,  0.2300,\n",
       "           0.3295, -0.0435, -0.1222, -0.0872,  0.1404, -0.1983, -0.0771,\n",
       "          -0.1422,  0.5138,  0.5273,  0.1412],\n",
       "         [-0.0804,  0.3473, -0.2274, -0.1240, -0.0057,  0.3051,  0.1226,\n",
       "           0.2555, -0.1163, -0.2704, -0.0075, -0.0185, -0.2498,  0.0650,\n",
       "           0.3498,  0.2934,  0.5193,  0.0358],\n",
       "         [-0.0931,  0.2079, -0.2087, -0.0306,  0.1332,  0.3605,  0.2494,\n",
       "           0.3168, -0.0247, -0.2485,  0.0553,  0.0025, -0.0785,  0.0341,\n",
       "           0.1837,  0.2606,  0.5454, -0.0736]],\n",
       "\n",
       "        [[-0.6910, -0.1860, -0.0429,  0.4113, -0.4726,  0.1205,  0.0144,\n",
       "           0.0335, -0.1235,  0.2319, -0.4612,  0.3753, -0.5560, -0.3359,\n",
       "          -0.5808,  0.3521,  0.1915,  0.1376],\n",
       "         [-0.4432, -0.0200, -0.1760,  0.2633, -0.1150,  0.4216,  0.2300,\n",
       "           0.3295, -0.0435, -0.1222, -0.0872,  0.1404, -0.1983, -0.0771,\n",
       "          -0.1422,  0.5138,  0.5273,  0.1412],\n",
       "         [-0.0804,  0.3473, -0.2274, -0.1240, -0.0057,  0.3051,  0.1226,\n",
       "           0.2555, -0.1163, -0.2704, -0.0075, -0.0185, -0.2498,  0.0650,\n",
       "           0.3498,  0.2934,  0.5193,  0.0358],\n",
       "         [-0.0931,  0.2079, -0.2087, -0.0306,  0.1332,  0.3605,  0.2494,\n",
       "           0.3168, -0.0247, -0.2485,  0.0553,  0.0025, -0.0785,  0.0341,\n",
       "           0.1837,  0.2606,  0.5454, -0.0736]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3226d617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 18])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d78d55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        # As in `CausalAttention`, for inputs where `num_tokens` exceeds `context_length`, \n",
    "        # this will result in errors in the mask creation further below. \n",
    "        # In practice, this is not a problem since the LLM (chapters 4-7) ensures that inputs  \n",
    "        # do not exceed `context_length` before reaching this forward method.\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55874c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c72fa018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3759,  0.0686,  0.7031,  0.0935, -0.0464, -0.4952,  0.8338,\n",
       "           1.1267],\n",
       "         [-0.6018, -0.2695,  0.3440, -1.1668, -0.9852,  0.4084, -0.0257,\n",
       "          -0.0238],\n",
       "         [-1.0834, -0.8992, -0.9997, -1.0471,  0.6966,  1.0558, -0.3086,\n",
       "           0.1166],\n",
       "         [-0.8312,  0.2855, -0.0538, -0.3936, -1.2552, -0.2012, -0.8806,\n",
       "          -0.0192]],\n",
       "\n",
       "        [[ 0.3759,  0.0686,  0.7031,  0.0935, -0.0464, -0.4952,  0.8338,\n",
       "           1.1267],\n",
       "         [-0.6018, -0.2695,  0.3440, -1.1668, -0.9852,  0.4084, -0.0257,\n",
       "          -0.0238],\n",
       "         [-1.0834, -0.8992, -0.9997, -1.0471,  0.6966,  1.0558, -0.3086,\n",
       "           0.1166],\n",
       "         [-0.8312,  0.2855, -0.0538, -0.3936, -1.2552, -0.2012, -0.8806,\n",
       "          -0.0192]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2fe1dfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3759,  0.0686,  0.7031,  0.0935],\n",
       "          [-0.0464, -0.4952,  0.8338,  1.1267]],\n",
       "\n",
       "         [[-0.6018, -0.2695,  0.3440, -1.1668],\n",
       "          [-0.9852,  0.4084, -0.0257, -0.0238]],\n",
       "\n",
       "         [[-1.0834, -0.8992, -0.9997, -1.0471],\n",
       "          [ 0.6966,  1.0558, -0.3086,  0.1166]],\n",
       "\n",
       "         [[-0.8312,  0.2855, -0.0538, -0.3936],\n",
       "          [-1.2552, -0.2012, -0.8806, -0.0192]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3759,  0.0686,  0.7031,  0.0935],\n",
       "          [-0.0464, -0.4952,  0.8338,  1.1267]],\n",
       "\n",
       "         [[-0.6018, -0.2695,  0.3440, -1.1668],\n",
       "          [-0.9852,  0.4084, -0.0257, -0.0238]],\n",
       "\n",
       "         [[-1.0834, -0.8992, -0.9997, -1.0471],\n",
       "          [ 0.6966,  1.0558, -0.3086,  0.1166]],\n",
       "\n",
       "         [[-0.8312,  0.2855, -0.0538, -0.3936],\n",
       "          [-1.2552, -0.2012, -0.8806, -0.0192]]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.view( 2, 4, 2, 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c2ab6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention( d_in = 8, d_out = 6, context_length=4, dropout=0, num_heads=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "827eb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_out = mha( batches )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b0d0409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1022,  0.1277, -0.4494,  0.2542, -0.3572,  0.1069],\n",
       "         [ 0.3136, -0.0460, -0.4749,  0.1109, -0.1989,  0.0882],\n",
       "         [ 0.3183, -0.1529, -0.3511,  0.0830, -0.1742,  0.0765],\n",
       "         [ 0.3105, -0.1777, -0.3346,  0.0754, -0.1344,  0.0482]],\n",
       "\n",
       "        [[ 0.1022,  0.1277, -0.4494,  0.2542, -0.3572,  0.1069],\n",
       "         [ 0.3136, -0.0460, -0.4749,  0.1109, -0.1989,  0.0882],\n",
       "         [ 0.3183, -0.1529, -0.3511,  0.0830, -0.1742,  0.0765],\n",
       "         [ 0.3105, -0.1777, -0.3346,  0.0754, -0.1344,  0.0482]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76c1c99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 6])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57eb0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbrudd/LLMs/blob/main/trainable_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c33a1a1",
      "metadata": {
        "id": "7c33a1a1"
      },
      "source": [
        "# Attention with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c78b079a",
      "metadata": {
        "id": "c78b079a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d1c0c81b",
      "metadata": {
        "id": "d1c0c81b"
      },
      "outputs": [],
      "source": [
        "inputs = torch.nn.Embedding( 4, 8 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.weight\n",
        "inputs"
      ],
      "metadata": {
        "id": "oNX4cULRxBVk",
        "outputId": "bf533d32-7ab7-4a18-9199-4831562708d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oNX4cULRxBVk",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.2427,  0.6827,  0.7656,  1.0912,  1.2138,  0.6371, -0.5461, -0.3942],\n",
              "        [-1.4937,  1.5845,  2.5122, -0.6860,  0.8015, -1.1129, -0.2717,  0.0380],\n",
              "        [-0.1699, -0.4934, -1.0443,  1.7926, -0.5786, -0.3779,  0.4462,  0.0745],\n",
              "        [-0.0711,  1.5781,  1.1288, -1.0967,  0.1295,  0.0320,  0.7134,  0.6368]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.data\n",
        "inputs"
      ],
      "metadata": {
        "id": "sTBV2KZYxCLY",
        "outputId": "7a7441ce-d882-4b7d-8823-43e7c0d9f49d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sTBV2KZYxCLY",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2427,  0.6827,  0.7656,  1.0912,  1.2138,  0.6371, -0.5461, -0.3942],\n",
              "        [-1.4937,  1.5845,  2.5122, -0.6860,  0.8015, -1.1129, -0.2717,  0.0380],\n",
              "        [-0.1699, -0.4934, -1.0443,  1.7926, -0.5786, -0.3779,  0.4462,  0.0745],\n",
              "        [-0.0711,  1.5781,  1.1288, -1.0967,  0.1295,  0.0320,  0.7134,  0.6368]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set dimensions\n",
        "d_in = 8\n",
        "d_out = 6\n",
        "\n",
        "# create weight matrices\n",
        "W_q = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_k = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_v = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )"
      ],
      "metadata": {
        "id": "QOwlthXbxb38"
      },
      "id": "QOwlthXbxb38",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose an input vector and transform it into our query vector using W_q\n",
        "query = inputs[2] @ W_q\n",
        "query"
      ],
      "metadata": {
        "id": "sNXSVRxtyUEq",
        "outputId": "4fe17bbf-ced8-46dc-e34d-0fff0c6f0d3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sNXSVRxtyUEq",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0585, -0.4860, -0.1032, -0.4076, -0.9160, -0.1425])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate attention scores using the keys generated by W_k:\n",
        "keys = inputs @ W_k\n",
        "values = inputs @ W_v\n",
        "print(\"Keys:\", keys)\n",
        "print(\"Values:\", values )"
      ],
      "metadata": {
        "id": "krMfHBPty33R",
        "outputId": "36438707-eb94-4b85-fe7a-ccd7e92f7a03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "krMfHBPty33R",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: tensor([[ 2.1480,  1.5529,  2.8008,  1.8782,  1.4580,  2.5026],\n",
            "        [ 1.9040,  0.2781,  1.9731,  1.5060,  0.9453,  2.0697],\n",
            "        [-0.1213, -1.5318, -0.1547, -0.1155, -1.1343, -0.8727],\n",
            "        [ 1.4671,  1.2422,  1.8308,  1.1122,  2.4337,  2.2144]])\n",
            "Values: tensor([[ 1.9701,  2.1980,  0.8614,  1.3574,  1.4857,  1.2846],\n",
            "        [-0.5965, -0.5286, -0.9120, -0.4883, -0.2370,  0.1408],\n",
            "        [ 0.6044,  0.3491, -0.2306,  0.4990, -0.1373, -1.1075],\n",
            "        [-0.0115,  0.2653,  1.3765,  1.7680,  0.7499,  2.0855]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_scores = query @ keys.T\n",
        "attention_scores"
      ],
      "metadata": {
        "id": "ZCYUxgufzYJx",
        "outputId": "7e9c9241-c8e1-4050-a98f-90c15f9784ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZCYUxgufzYJx",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.6272, -2.2249,  1.9780, -3.8767])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = torch.softmax( attention_scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "attention_weights"
      ],
      "metadata": {
        "id": "8E3nKiYMz-B3",
        "outputId": "7be3feb4-bbc4-4b3e-93f7-f73d3592d996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8E3nKiYMz-B3",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0739, 0.1310, 0.7284, 0.0667])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights.sum()"
      ],
      "metadata": {
        "id": "ivp5ajUU0hVX",
        "outputId": "3d728c16-7da8-47e1-9f90-dfe88ae97494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ivp5ajUU0hVX",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector = attention_weights @ values\n",
        "context_vector"
      ],
      "metadata": {
        "id": "NDyjIXnw01bw",
        "outputId": "77c652e1-60bf-4708-b3ab-3b48762a4538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NDyjIXnw01bw",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5069,  0.3652, -0.1319,  0.5178,  0.0287, -0.5542])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "mDJu60I-08oe"
      },
      "id": "mDJu60I-08oe",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's a first version of a SimpleAttention class:\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_k = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_v = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = x @ self.W_q\n",
        "    keys = x @ self.W_k\n",
        "    values = x @ self.W_v\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ],
      "metadata": {
        "id": "nCNgyvAjDqJx"
      },
      "id": "nCNgyvAjDqJx",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ],
      "metadata": {
        "id": "WGqfizBVGQ6H"
      },
      "id": "WGqfizBVGQ6H",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple.W_v"
      ],
      "metadata": {
        "id": "m8khSsLLGbPx",
        "outputId": "83c97ed1-6c15-4aa0-c1aa-2b1c9817df8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "m8khSsLLGbPx",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.0302, 0.6970, 0.2217, 0.3603, 0.3794, 0.4925],\n",
              "        [0.0935, 0.1134, 0.4462, 0.7525, 0.9334, 0.5044],\n",
              "        [0.9820, 0.6072, 0.5998, 0.3263, 0.8216, 0.8495],\n",
              "        [0.1017, 0.0541, 0.4583, 0.2478, 0.7052, 0.4103],\n",
              "        [0.9067, 0.6691, 0.6662, 0.0422, 0.9965, 0.8874],\n",
              "        [0.3491, 0.1067, 0.6210, 0.0992, 0.8924, 0.7328],\n",
              "        [0.2464, 0.4291, 0.8142, 0.2558, 0.9035, 0.7506],\n",
              "        [0.2434, 0.7094, 0.7889, 0.8098, 0.3994, 0.2009]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ],
      "metadata": {
        "id": "IDXEWBn2GhTu",
        "outputId": "d9483eba-77bf-4458-acdc-1363e90757a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IDXEWBn2GhTu",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.6600, 1.5125, 2.0004, 1.8163, 2.6899, 2.0961],\n",
              "        [1.8196, 1.1861, 1.8020, 1.3035, 2.7585, 2.1389],\n",
              "        [1.5107, 0.8079, 1.3080, 1.0829, 1.9705, 1.4535],\n",
              "        [1.7056, 1.4171, 1.9554, 1.6537, 2.7418, 2.1345]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here's a second version of a SimpleAttention class ;\n",
        "# it uses nn.Linear to do things more efficiently\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ],
      "metadata": {
        "id": "j0J4KZOZGqfu"
      },
      "id": "j0J4KZOZGqfu",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ],
      "metadata": {
        "id": "Zki5jtLCI6Cu"
      },
      "id": "Zki5jtLCI6Cu",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ],
      "metadata": {
        "id": "k6LcTWL9I8te",
        "outputId": "f4f6f2d6-079c-4c85-9210-7a3c6bf76b02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k6LcTWL9I8te",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.1225e-02, -3.6173e-01,  2.8266e-01, -3.3615e-01, -7.9088e-05,\n",
              "          3.5463e-01],\n",
              "        [-1.0249e-01, -3.7105e-01,  2.8051e-01, -2.6390e-01, -5.1291e-02,\n",
              "          2.8341e-01],\n",
              "        [-9.4526e-02, -2.0338e-01,  1.5570e-01, -1.6162e-01,  8.7017e-02,\n",
              "          8.3274e-02],\n",
              "        [-1.0312e-01, -3.3303e-01,  2.4755e-01, -2.3086e-01, -1.6659e-02,\n",
              "          2.2562e-01]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the problem with this is that each context vector uses information from ALL of the embedding vectors\n",
        "# in practice, we should only use information about the preceding embedding vectors\n",
        "# to accomplish this, we'll implement causal attention AKA masked attention"
      ],
      "metadata": {
        "id": "oue7IwuyI_ON"
      },
      "id": "oue7IwuyI_ON",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a hack to get some example weights to work with!\n",
        "# weights = simple( inputs )\n",
        "weights"
      ],
      "metadata": {
        "id": "L734IABHc89l",
        "outputId": "d3baf755-2800-4380-d368-aca36fc58adb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "L734IABHc89l",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2687, 0.2787, 0.1943, 0.2583],\n",
              "        [0.3065, 0.2572, 0.1634, 0.2729],\n",
              "        [0.1916, 0.2275, 0.3366, 0.2443],\n",
              "        [0.2878, 0.2422, 0.2345, 0.2355]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note that these have already been normalized:\n",
        "weights.sum( dim=-1 )"
      ],
      "metadata": {
        "id": "SiNiJA_tdnIr",
        "outputId": "a0b95c43-6209-4884-ef27-c09babf578a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SiNiJA_tdnIr",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# masking method #1\n",
        "simple_mask = torch.tril( torch.ones( weights.shape[0], weights.shape[0] ) )\n",
        "simple_mask"
      ],
      "metadata": {
        "id": "w8qwVBb3d5YE",
        "outputId": "91908225-ad9d-429f-9feb-41559e43afcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "w8qwVBb3d5YE",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0.],\n",
              "        [1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights = weights*simple_mask\n",
        "masked_weights"
      ],
      "metadata": {
        "id": "aPN1GiEdeWq_",
        "outputId": "076493fd-32eb-4fbb-fb27-2d71ed7c8da9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aPN1GiEdeWq_",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2687, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3065, 0.2572, 0.0000, 0.0000],\n",
              "        [0.1916, 0.2275, 0.3366, 0.0000],\n",
              "        [0.2878, 0.2422, 0.2345, 0.2355]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights.sum( dim=-1 )"
      ],
      "metadata": {
        "id": "N-Ifwx0EfJs9",
        "outputId": "ac5c40b5-443a-4b61-b330-7e09933e052a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "N-Ifwx0EfJs9",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2687, 0.5637, 0.7557, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now, we need to normalize the masked_weights so that each row has sum 1\n",
        "row_sums = masked_weights.sum( dim=-1, keepdim=True)\n",
        "row_sums"
      ],
      "metadata": {
        "id": "gbOrqXGSfbm2",
        "outputId": "776e5184-5094-459f-82bb-c71d1a27612b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gbOrqXGSfbm2",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2687],\n",
              "        [0.5637],\n",
              "        [0.7557],\n",
              "        [1.0000]], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights = masked_weights / row_sums\n",
        "masked_weights.sum( dim=-1)"
      ],
      "metadata": {
        "id": "ACdob5jyfi2P",
        "outputId": "ac8441ef-1062-437a-d640-31efeb9c7a6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ACdob5jyfi2P",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights"
      ],
      "metadata": {
        "id": "0_aQEYcQf4tB",
        "outputId": "bc7275db-146c-4e00-d521-ceb4b0abdd29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0_aQEYcQf4tB",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5437, 0.4563, 0.0000, 0.0000],\n",
              "        [0.2536, 0.3010, 0.4455, 0.0000],\n",
              "        [0.2878, 0.2422, 0.2345, 0.2355]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# masking method #2\n",
        "mask = torch.triu( torch.ones(weights.shape[0], weights.shape[0]), diagonal = 1 )\n",
        "mask"
      ],
      "metadata": {
        "id": "QxaUROkpgBmr",
        "outputId": "19c68189-cc59-4e7e-88fd-13116854c6ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QxaUROkpgBmr",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask.bool()"
      ],
      "metadata": {
        "id": "9aAkggNUhUAs",
        "outputId": "01ca9d8c-e586-4301-b5c6-fc8fc6a85875",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9aAkggNUhUAs",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  True],\n",
              "        [False, False,  True,  True],\n",
              "        [False, False, False,  True],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "id": "84ev4pTZhoLD",
        "outputId": "dc355d81-9336-457d-af14-4b7d03cf728b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "84ev4pTZhoLD",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2687, 0.2787, 0.1943, 0.2583],\n",
              "        [0.3065, 0.2572, 0.1634, 0.2729],\n",
              "        [0.1916, 0.2275, 0.3366, 0.2443],\n",
              "        [0.2878, 0.2422, 0.2345, 0.2355]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = weights.masked_fill( mask.bool(), -torch.inf )\n",
        "weights"
      ],
      "metadata": {
        "id": "7AW_dLvCgiA8",
        "outputId": "201749c3-b038-4aeb-cad3-680f612701a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7AW_dLvCgiA8",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2687,   -inf,   -inf,   -inf],\n",
              "        [0.3065, 0.2572,   -inf,   -inf],\n",
              "        [0.1916, 0.2275, 0.3366,   -inf],\n",
              "        [0.2878, 0.2422, 0.2345, 0.2355]], grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights = torch.softmax( weights, dim=-1 )\n",
        "masked_weights"
      ],
      "metadata": {
        "id": "mMquJ-g1hvuq",
        "outputId": "832c13f1-13fb-43a7-db07-0703b88cdedd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mMquJ-g1hvuq",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5123, 0.4877, 0.0000, 0.0000],\n",
              "        [0.3132, 0.3247, 0.3621, 0.0000],\n",
              "        [0.2596, 0.2480, 0.2461, 0.2463]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dropout\n",
        "# idea: randomly select some data to leave out to avoid overfitting\n",
        "dropout = nn.Dropout( 0.5 )"
      ],
      "metadata": {
        "id": "v0Rl7yaikQwW"
      },
      "id": "v0Rl7yaikQwW",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout( masked_weights )"
      ],
      "metadata": {
        "id": "Js4JQ6b9lN1p",
        "outputId": "1ce7a802-c040-47a4-93a1-3fb39248b5a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Js4JQ6b9lN1p",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.4922, 0.4927]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to be able to give our LLM batches of input\n",
        "# for example:\n",
        "batches = torch.stack( (inputs, inputs), dim=0)"
      ],
      "metadata": {
        "id": "lwzL1olBjA62"
      },
      "id": "lwzL1olBjA62",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches"
      ],
      "metadata": {
        "id": "F9pE07dKjkPS",
        "outputId": "7c8abc7d-055c-4f1d-e79a-808d8df996a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F9pE07dKjkPS",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.2427,  0.6827,  0.7656,  1.0912,  1.2138,  0.6371, -0.5461,\n",
              "          -0.3942],\n",
              "         [-1.4937,  1.5845,  2.5122, -0.6860,  0.8015, -1.1129, -0.2717,\n",
              "           0.0380],\n",
              "         [-0.1699, -0.4934, -1.0443,  1.7926, -0.5786, -0.3779,  0.4462,\n",
              "           0.0745],\n",
              "         [-0.0711,  1.5781,  1.1288, -1.0967,  0.1295,  0.0320,  0.7134,\n",
              "           0.6368]],\n",
              "\n",
              "        [[-0.2427,  0.6827,  0.7656,  1.0912,  1.2138,  0.6371, -0.5461,\n",
              "          -0.3942],\n",
              "         [-1.4937,  1.5845,  2.5122, -0.6860,  0.8015, -1.1129, -0.2717,\n",
              "           0.0380],\n",
              "         [-0.1699, -0.4934, -1.0443,  1.7926, -0.5786, -0.3779,  0.4462,\n",
              "           0.0745],\n",
              "         [-0.0711,  1.5781,  1.1288, -1.0967,  0.1295,  0.0320,  0.7134,\n",
              "           0.6368]]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches.shape"
      ],
      "metadata": {
        "id": "ZcupJCg5zIrL",
        "outputId": "f0a40051-1080-4e1d-caeb-e49b1b2f9974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZcupJCg5zIrL",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this class needs to handle batches of input!\n",
        "\n",
        "class CausalAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "    # include dropout:\n",
        "    self.dropout = nn.Dropout( dropout )\n",
        "    # use the following to manage memory efficiently:\n",
        "    self.register_buffer(\n",
        "        'mask',\n",
        "        torch.triu( torch.ones(context_length, context_length), diagonal = 1 )\n",
        "    )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.transpose(1,2)\n",
        "    scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    weights = self.dropout( weights )\n",
        "    context = weights @ values\n",
        "    return context"
      ],
      "metadata": {
        "id": "uP2PuQ5RiCM8"
      },
      "id": "uP2PuQ5RiCM8",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate a causal attention mechanism:\n",
        "causal = CausalAttention( d_in=8, d_out=6, context_length=4, dropout=0 )"
      ],
      "metadata": {
        "id": "Tqglx-lp0TFn"
      },
      "id": "Tqglx-lp0TFn",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "causal( batches )"
      ],
      "metadata": {
        "id": "vl4s2kdd4iNi",
        "outputId": "020a098a-31b7-47c1-ef07-df80ddf5713f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vl4s2kdd4iNi",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.2956,  0.1039,  0.0676, -0.2119, -0.7519, -0.4160],\n",
              "         [ 0.0174, -0.0664, -0.5165, -0.7360, -1.3500, -0.3612],\n",
              "         [-0.4007,  0.0280, -0.0891, -0.4656, -0.5094, -0.2803],\n",
              "         [ 0.0916, -0.1431, -0.1039, -0.6458, -0.7593, -0.2148]],\n",
              "\n",
              "        [[-0.2956,  0.1039,  0.0676, -0.2119, -0.7519, -0.4160],\n",
              "         [ 0.0174, -0.0664, -0.5165, -0.7360, -1.3500, -0.3612],\n",
              "         [-0.4007,  0.0280, -0.0891, -0.4656, -0.5094, -0.2803],\n",
              "         [ 0.0916, -0.1431, -0.1039, -0.6458, -0.7593, -0.2148]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# everything below is just to show what happens with batches"
      ],
      "metadata": {
        "id": "sqLa6xcW0bPw"
      },
      "id": "sqLa6xcW0bPw",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = W_q( batches )\n",
        "queries"
      ],
      "metadata": {
        "id": "TxE4RKo20-h0",
        "outputId": "cb5d6181-0c7d-4589-ed84-5d48c6acef6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TxE4RKo20-h0",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.2929e-02, -5.1089e-02,  1.9729e-01,  1.4060e-01,  1.1246e-03,\n",
              "           2.1223e-01],\n",
              "         [ 1.2751e+00,  1.2309e+00, -2.6176e-01,  1.3619e+00,  5.4810e-01,\n",
              "          -1.9892e-01],\n",
              "         [-7.6839e-01,  8.0788e-02,  5.8067e-01, -1.6036e-01, -8.1724e-01,\n",
              "           7.5022e-01],\n",
              "         [ 8.3302e-01,  6.2428e-01,  8.5691e-04,  7.7048e-01,  3.1241e-01,\n",
              "          -4.3753e-01]],\n",
              "\n",
              "        [[-3.2929e-02, -5.1089e-02,  1.9729e-01,  1.4060e-01,  1.1246e-03,\n",
              "           2.1223e-01],\n",
              "         [ 1.2751e+00,  1.2309e+00, -2.6176e-01,  1.3619e+00,  5.4810e-01,\n",
              "          -1.9892e-01],\n",
              "         [-7.6839e-01,  8.0788e-02,  5.8067e-01, -1.6036e-01, -8.1724e-01,\n",
              "           7.5022e-01],\n",
              "         [ 8.3302e-01,  6.2428e-01,  8.5691e-04,  7.7048e-01,  3.1241e-01,\n",
              "          -4.3753e-01]]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = W_k( batches )\n",
        "keys"
      ],
      "metadata": {
        "id": "oXOqIeOi0_pX",
        "outputId": "1cbcc53f-dcb1-43e6-8e33-3e894ede0feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oXOqIeOi0_pX",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.2261, -0.3120,  0.0810, -0.2931, -0.8426, -0.4877],\n",
              "         [ 0.0451, -0.1597,  0.1095,  0.7858, -0.6787, -0.8029],\n",
              "         [ 0.4853,  0.2652, -0.1591, -0.0825,  0.7799,  0.3343],\n",
              "         [-0.5785, -0.2767,  0.4855,  0.1878, -0.5316, -0.8584]],\n",
              "\n",
              "        [[ 0.2261, -0.3120,  0.0810, -0.2931, -0.8426, -0.4877],\n",
              "         [ 0.0451, -0.1597,  0.1095,  0.7858, -0.6787, -0.8029],\n",
              "         [ 0.4853,  0.2652, -0.1591, -0.0825,  0.7799,  0.3343],\n",
              "         [-0.5785, -0.2767,  0.4855,  0.1878, -0.5316, -0.8584]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys.transpose(1,2)"
      ],
      "metadata": {
        "id": "skDtU7a31bAS",
        "outputId": "3498b8a9-fde1-47b2-ab74-84e61e23cdca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "skDtU7a31bAS",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.2261,  0.0451,  0.4853, -0.5785],\n",
              "         [-0.3120, -0.1597,  0.2652, -0.2767],\n",
              "         [ 0.0810,  0.1095, -0.1591,  0.4855],\n",
              "         [-0.2931,  0.7858, -0.0825,  0.1878],\n",
              "         [-0.8426, -0.6787,  0.7799, -0.5316],\n",
              "         [-0.4877, -0.8029,  0.3343, -0.8584]],\n",
              "\n",
              "        [[ 0.2261,  0.0451,  0.4853, -0.5785],\n",
              "         [-0.3120, -0.1597,  0.2652, -0.2767],\n",
              "         [ 0.0810,  0.1095, -0.1591,  0.4855],\n",
              "         [-0.2931,  0.7858, -0.0825,  0.1878],\n",
              "         [-0.8426, -0.6787,  0.7799, -0.5316],\n",
              "         [-0.4877, -0.8029,  0.3343, -0.8584]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4-NOY2s91p61"
      },
      "id": "4-NOY2s91p61",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
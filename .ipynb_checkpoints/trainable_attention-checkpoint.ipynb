{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d9f3bcb",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mbrudd/LLMs/blob/main/trainable_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33a1a1",
   "metadata": {
    "id": "7c33a1a1"
   },
   "source": [
    "# Attention with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c78b079a",
   "metadata": {
    "id": "c78b079a"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c0c81b",
   "metadata": {
    "id": "d1c0c81b"
   },
   "outputs": [],
   "source": [
    "inputs = torch.nn.Embedding( 4, 8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "oNX4cULRxBVk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNX4cULRxBVk",
    "outputId": "bf533d32-7ab7-4a18-9199-4831562708d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1197, -1.2762, -0.2189, -0.5249, -0.7863, -0.6896,  0.9719, -0.7062],\n",
       "        [-0.7043,  0.6678,  1.3428,  0.9279, -0.1171,  0.9757, -0.4852,  0.2322],\n",
       "        [ 0.3666,  0.4479, -0.5973, -0.4069, -1.2787,  1.4757,  2.2668,  0.9394],\n",
       "        [-2.5224, -1.7426, -0.7029,  0.6029,  1.8368, -0.1128, -0.9829, -0.3613]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.weight\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sTBV2KZYxCLY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTBV2KZYxCLY",
    "outputId": "7a7441ce-d882-4b7d-8823-43e7c0d9f49d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1197, -1.2762, -0.2189, -0.5249, -0.7863, -0.6896,  0.9719, -0.7062],\n",
       "        [-0.7043,  0.6678,  1.3428,  0.9279, -0.1171,  0.9757, -0.4852,  0.2322],\n",
       "        [ 0.3666,  0.4479, -0.5973, -0.4069, -1.2787,  1.4757,  2.2668,  0.9394],\n",
       "        [-2.5224, -1.7426, -0.7029,  0.6029,  1.8368, -0.1128, -0.9829, -0.3613]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.data\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "QOwlthXbxb38",
   "metadata": {
    "id": "QOwlthXbxb38"
   },
   "outputs": [],
   "source": [
    "# set dimensions\n",
    "d_in = 8\n",
    "d_out = 6\n",
    "\n",
    "# create weight matrices\n",
    "W_q = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
    "W_k = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
    "W_v = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sNXSVRxtyUEq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNXSVRxtyUEq",
    "outputId": "4fe17bbf-ced8-46dc-e34d-0fff0c6f0d3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.2052, 0.9526, 2.5539, 1.3872, 0.1190, 2.2922])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose an input vector and transform it into our query vector using W_q\n",
    "query = inputs[2] @ W_q\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "krMfHBPty33R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "krMfHBPty33R",
    "outputId": "36438707-eb94-4b85-fe7a-ccd7e92f7a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: tensor([[-1.8804,  0.0284, -2.0566, -1.9059, -1.0583, -1.6339],\n",
      "        [ 2.1169,  0.6069,  1.2166,  1.4986,  1.1167,  1.0354],\n",
      "        [ 2.5898,  1.8816,  0.9269,  1.4456,  2.1721,  1.9620],\n",
      "        [-3.3770, -2.4154, -2.6265, -3.2443, -2.4173, -2.1509]])\n",
      "Values: tensor([[-1.6695, -1.8921, -1.7313, -1.4193, -1.6749, -2.5785],\n",
      "        [ 1.0467,  2.2443,  1.5191,  1.3044,  1.5846,  1.6639],\n",
      "        [ 1.1272,  1.2353, -0.9836,  1.2727,  2.4874, -0.0108],\n",
      "        [-0.7975, -0.8695, -1.7951, -1.4770, -1.8175, -0.7950]])\n"
     ]
    }
   ],
   "source": [
    "# calculate attention scores using the keys generated by W_k:\n",
    "keys = inputs @ W_k\n",
    "values = inputs @ W_v\n",
    "print(\"Keys:\", keys)\n",
    "print(\"Values:\", values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ZCYUxgufzYJx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCYUxgufzYJx",
    "outputId": "7e9c9241-c8e1-4050-a98f-90c15f9784ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-17.7671,  15.0553,  19.2218, -29.5513])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = query @ keys.T\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8E3nKiYMz-B3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8E3nKiYMz-B3",
    "outputId": "7be3feb4-bbc4-4b3e-93f7-f73d3592d996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3392e-07, 1.5434e-01, 8.4566e-01, 1.9042e-09])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = torch.softmax( attention_scores / keys.shape[-1]**0.5, dim = -1 )\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ivp5ajUU0hVX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivp5ajUU0hVX",
    "outputId": "3d728c16-7da8-47e1-9f90-dfe88ae97494"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "NDyjIXnw01bw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDyjIXnw01bw",
    "outputId": "77c652e1-60bf-4708-b3ab-3b48762a4538"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1148,  1.3910, -0.5974,  1.2776,  2.3481,  0.2477])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector = attention_weights @ values\n",
    "context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mDJu60I-08oe",
   "metadata": {
    "id": "mDJu60I-08oe"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nCNgyvAjDqJx",
   "metadata": {
    "id": "nCNgyvAjDqJx"
   },
   "outputs": [],
   "source": [
    "# here's a first version of a SimpleAttention class:\n",
    "\n",
    "class SimpleAttention( nn.Module ):\n",
    "  def __init__(self, d_in, d_out):\n",
    "    super().__init__()\n",
    "    # create weight matrices:\n",
    "    self.W_q = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
    "    self.W_k = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
    "    self.W_v = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
    "\n",
    "  # x = embedding vectors (inputs)\n",
    "  def forward( self, x ):\n",
    "    queries = x @ self.W_q\n",
    "    keys = x @ self.W_k\n",
    "    values = x @ self.W_v\n",
    "    scores = queries @ keys.T\n",
    "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
    "    context = weights @ values\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "WGqfizBVGQ6H",
   "metadata": {
    "id": "WGqfizBVGQ6H"
   },
   "outputs": [],
   "source": [
    "# here's how to use this class:\n",
    "# instantiate an instance of it:\n",
    "simple = SimpleAttention( d_in = 8, d_out = 6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "m8khSsLLGbPx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8khSsLLGbPx",
    "outputId": "83c97ed1-6c15-4aa0-c1aa-2b1c9817df8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.4066, 0.7928, 0.5265, 0.9394, 0.7186, 0.0932],\n",
       "        [0.3120, 0.7668, 0.3172, 0.5927, 0.6998, 0.7964],\n",
       "        [0.6131, 0.4812, 0.8247, 0.0656, 0.5676, 0.1964],\n",
       "        [0.6455, 0.7282, 0.4283, 0.1087, 0.1954, 0.0595],\n",
       "        [0.0476, 0.6367, 0.5483, 0.8005, 0.4652, 0.5812],\n",
       "        [0.3759, 0.5771, 0.1766, 0.4067, 0.2624, 0.3073],\n",
       "        [0.6372, 0.4309, 0.9647, 0.2889, 0.5187, 0.4210],\n",
       "        [0.2237, 0.7635, 0.2370, 0.3275, 0.4569, 0.0820]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple.W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "IDXEWBn2GhTu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDXEWBn2GhTu",
    "outputId": "d9483eba-77bf-4458-acdc-1363e90757a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6837, -2.6692, -1.6217, -2.0741, -2.5194, -1.2305],\n",
       "        [ 1.5106,  1.7405,  1.1445,  0.3192,  1.0640,  0.8593],\n",
       "        [ 1.4877,  1.7378,  1.1063,  0.2613,  1.0260,  0.8493],\n",
       "        [-1.2451, -2.5502, -1.1549, -1.8611, -2.0405, -1.3020]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = simple( inputs )\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "j0J4KZOZGqfu",
   "metadata": {
    "id": "j0J4KZOZGqfu"
   },
   "outputs": [],
   "source": [
    "# here's a second version of a SimpleAttention class ;\n",
    "# it uses nn.Linear to do things more efficiently\n",
    "\n",
    "class SimpleAttention( nn.Module ):\n",
    "  def __init__(self, d_in, d_out):\n",
    "    super().__init__()\n",
    "    # create weight matrices:\n",
    "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
    "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
    "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
    "\n",
    "  # x = embedding vectors (inputs)\n",
    "  def forward( self, x ):\n",
    "    queries = self.W_q( x )\n",
    "    keys = self.W_k( x )\n",
    "    values = self.W_v( x )\n",
    "    scores = queries @ keys.T\n",
    "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
    "    context = weights @ values\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Zki5jtLCI6Cu",
   "metadata": {
    "id": "Zki5jtLCI6Cu"
   },
   "outputs": [],
   "source": [
    "# here's how to use this class:\n",
    "# instantiate an instance of it:\n",
    "simple = SimpleAttention( d_in = 8, d_out = 6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "k6LcTWL9I8te",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6LcTWL9I8te",
    "outputId": "f4f6f2d6-079c-4c85-9210-7a3c6bf76b02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2893,  0.1132, -0.0358,  0.1293, -0.1353, -0.0383],\n",
       "        [ 0.2967,  0.1351, -0.0425,  0.0905, -0.1454, -0.1069],\n",
       "        [ 0.1528, -0.0386, -0.1008,  0.2598, -0.1097,  0.1222],\n",
       "        [ 0.2973,  0.1407, -0.0467,  0.0750, -0.1486, -0.1330]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = simple( inputs )\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "oue7IwuyI_ON",
   "metadata": {
    "id": "oue7IwuyI_ON"
   },
   "outputs": [],
   "source": [
    "# the problem with this is that each context vector uses information from ALL of the embedding vectors\n",
    "# in practice, we should only use information about the preceding embedding vectors\n",
    "# to accomplish this, we'll implement causal attention AKA masked attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L734IABHc89l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L734IABHc89l",
    "outputId": "d3baf755-2800-4380-d368-aca36fc58adb"
   },
   "outputs": [],
   "source": [
    "# this is a hack to get some example weights to work with!\n",
    "# weights = simple( inputs )\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SiNiJA_tdnIr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiNiJA_tdnIr",
    "outputId": "a0b95c43-6209-4884-ef27-c09babf578a6"
   },
   "outputs": [],
   "source": [
    "# note that these have already been normalized:\n",
    "weights.sum( dim=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w8qwVBb3d5YE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8qwVBb3d5YE",
    "outputId": "91908225-ad9d-429f-9feb-41559e43afcf"
   },
   "outputs": [],
   "source": [
    "# masking method #1\n",
    "simple_mask = torch.tril( torch.ones( weights.shape[0], weights.shape[0] ) )\n",
    "simple_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aPN1GiEdeWq_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPN1GiEdeWq_",
    "outputId": "076493fd-32eb-4fbb-fb27-2d71ed7c8da9"
   },
   "outputs": [],
   "source": [
    "masked_weights = weights*simple_mask\n",
    "masked_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N-Ifwx0EfJs9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-Ifwx0EfJs9",
    "outputId": "ac5c40b5-443a-4b61-b330-7e09933e052a"
   },
   "outputs": [],
   "source": [
    "masked_weights.sum( dim=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gbOrqXGSfbm2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbOrqXGSfbm2",
    "outputId": "776e5184-5094-459f-82bb-c71d1a27612b"
   },
   "outputs": [],
   "source": [
    "# now, we need to normalize the masked_weights so that each row has sum 1\n",
    "row_sums = masked_weights.sum( dim=-1, keepdim=True)\n",
    "row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ACdob5jyfi2P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACdob5jyfi2P",
    "outputId": "ac8441ef-1062-437a-d640-31efeb9c7a6f"
   },
   "outputs": [],
   "source": [
    "masked_weights = masked_weights / row_sums\n",
    "masked_weights.sum( dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0_aQEYcQf4tB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_aQEYcQf4tB",
    "outputId": "bc7275db-146c-4e00-d521-ceb4b0abdd29"
   },
   "outputs": [],
   "source": [
    "masked_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QxaUROkpgBmr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxaUROkpgBmr",
    "outputId": "19c68189-cc59-4e7e-88fd-13116854c6ef"
   },
   "outputs": [],
   "source": [
    "# masking method #2\n",
    "mask = torch.triu( torch.ones(weights.shape[0], weights.shape[0]), diagonal = 1 )\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aAkggNUhUAs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aAkggNUhUAs",
    "outputId": "01ca9d8c-e586-4301-b5c6-fc8fc6a85875"
   },
   "outputs": [],
   "source": [
    "mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ev4pTZhoLD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84ev4pTZhoLD",
    "outputId": "dc355d81-9336-457d-af14-4b7d03cf728b"
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7AW_dLvCgiA8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AW_dLvCgiA8",
    "outputId": "201749c3-b038-4aeb-cad3-680f612701a7"
   },
   "outputs": [],
   "source": [
    "weights = weights.masked_fill( mask.bool(), -torch.inf )\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mMquJ-g1hvuq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMquJ-g1hvuq",
    "outputId": "832c13f1-13fb-43a7-db07-0703b88cdedd"
   },
   "outputs": [],
   "source": [
    "masked_weights = torch.softmax( weights, dim=-1 )\n",
    "masked_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v0Rl7yaikQwW",
   "metadata": {
    "id": "v0Rl7yaikQwW"
   },
   "outputs": [],
   "source": [
    "## Dropout\n",
    "# idea: randomly select some data to leave out to avoid overfitting\n",
    "dropout = nn.Dropout( 0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Js4JQ6b9lN1p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Js4JQ6b9lN1p",
    "outputId": "1ce7a802-c040-47a4-93a1-3fb39248b5a5"
   },
   "outputs": [],
   "source": [
    "dropout( masked_weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lwzL1olBjA62",
   "metadata": {
    "id": "lwzL1olBjA62"
   },
   "outputs": [],
   "source": [
    "# we need to be able to give our LLM batches of input\n",
    "# for example:\n",
    "batches = torch.stack( (inputs, inputs), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F9pE07dKjkPS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9pE07dKjkPS",
    "outputId": "7c8abc7d-055c-4f1d-e79a-808d8df996a5"
   },
   "outputs": [],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZcupJCg5zIrL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcupJCg5zIrL",
    "outputId": "f0a40051-1080-4e1d-caeb-e49b1b2f9974"
   },
   "outputs": [],
   "source": [
    "batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uP2PuQ5RiCM8",
   "metadata": {
    "id": "uP2PuQ5RiCM8"
   },
   "outputs": [],
   "source": [
    "# this class needs to handle batches of input!\n",
    "\n",
    "class CausalAttention( nn.Module ):\n",
    "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "    super().__init__()\n",
    "    self.d_out = d_out\n",
    "    # create weight matrices:\n",
    "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
    "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
    "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
    "    # include dropout:\n",
    "    self.dropout = nn.Dropout( dropout )\n",
    "    # use the following to manage memory efficiently:\n",
    "    self.register_buffer(\n",
    "        'mask',\n",
    "        torch.triu( torch.ones(context_length, context_length), diagonal = 1 )\n",
    "    )\n",
    "\n",
    "  # x = embedding vectors (inputs)\n",
    "  def forward( self, x ):\n",
    "    b, num_tokens, d_in = x.shape\n",
    "    queries = self.W_q( x )\n",
    "    keys = self.W_k( x )\n",
    "    values = self.W_v( x )\n",
    "    scores = queries @ keys.transpose(1,2)\n",
    "    scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
    "    weights = self.dropout( weights )\n",
    "    context = weights @ values\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tqglx-lp0TFn",
   "metadata": {
    "id": "Tqglx-lp0TFn"
   },
   "outputs": [],
   "source": [
    "# instantiate a causal attention mechanism:\n",
    "causal = CausalAttention( d_in=8, d_out=6, context_length=4, dropout=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vl4s2kdd4iNi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vl4s2kdd4iNi",
    "outputId": "020a098a-31b7-47c1-ef07-df80ddf5713f"
   },
   "outputs": [],
   "source": [
    "causal( batches )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sqLa6xcW0bPw",
   "metadata": {
    "id": "sqLa6xcW0bPw"
   },
   "outputs": [],
   "source": [
    "# everything below is just to show what happens with batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TxE4RKo20-h0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxE4RKo20-h0",
    "outputId": "cb5d6181-0c7d-4589-ed84-5d48c6acef6e"
   },
   "outputs": [],
   "source": [
    "queries = W_q( batches )\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oXOqIeOi0_pX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXOqIeOi0_pX",
    "outputId": "1cbcc53f-dcb1-43e6-8e33-3e894ede0feb"
   },
   "outputs": [],
   "source": [
    "keys = W_k( batches )\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skDtU7a31bAS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skDtU7a31bAS",
    "outputId": "3498b8a9-fde1-47b2-ab74-84e61e23cdca"
   },
   "outputs": [],
   "source": [
    "keys.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4-NOY2s91p61",
   "metadata": {
    "id": "4-NOY2s91p61"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
